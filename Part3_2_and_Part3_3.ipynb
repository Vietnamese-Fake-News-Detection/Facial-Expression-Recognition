{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eef98ff",
   "metadata": {},
   "source": [
    "# Facial Expression Recognition\n",
    "\n",
    "Nguyễn Hữu Phong - BIT240181 - Leader\n",
    "\n",
    "Triệu Hồng Quân - BIT240188\n",
    "\n",
    "Trần Hoàng Hải - BIT240084\n",
    "\n",
    "---\n",
    "\n",
    "#### FILE 2: PART 3.2 - PART 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b6dfc",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 3.2: Architecture Analysis Questions (2 marks)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c83a5",
   "metadata": {},
   "source": [
    "## Question 3.2.a) MaxPooling Layer Analysis (Purpose and Spatial Dimension Changes)\n",
    "\n",
    "### Purpose of MaxPooling Layer:\n",
    "\n",
    "**MaxPooling** là một lớp giảm chiều (downsampling layer) trong mạng neural tích chập với các mục đích chính:\n",
    "\n",
    "1. **Giảm kích thước không gian (Spatial Dimension Reduction)**:\n",
    "   - Giảm số lượng tham số và khối lượng tính toán trong mạng\n",
    "   - Giúp kiểm soát overfitting bằng cách cung cấp một dạng trừu tượng hóa\n",
    "\n",
    "2. **Trích xuất đặc trưng nổi bật (Feature Extraction)**:\n",
    "   - Chọn giá trị lớn nhất trong mỗi vùng, giữ lại các đặc trưng quan trọng nhất\n",
    "   - Loại bỏ các thông tin ít quan trọng, giữ lại các activation mạnh nhất\n",
    "\n",
    "3. **Tạo tính bất biến vị trí (Translation Invariance)**:\n",
    "   - Giúp mô hình nhận dạng đối tượng bất kể vị trí chính xác trong ảnh\n",
    "   - Các đặc trưng được nhận dạng dù có dịch chuyển nhỏ\n",
    "\n",
    "4. **Mở rộng receptive field**:\n",
    "   - Cho phép các lớp sau \"nhìn\" được vùng lớn hơn của ảnh đầu vào\n",
    "\n",
    "### Phân tích thay đổi kích thước khi thay đổi MaxPooling:\n",
    "\n",
    "**Công thức tính kích thước đầu ra:**\n",
    "\n",
    "$$\\text{Output Size} = \\left\\lfloor \\frac{W - K + 2P}{S} \\right\\rfloor + 1$$\n",
    "\n",
    "Trong đó:\n",
    "- W = Kích thước đầu vào (Width/Height)\n",
    "- K = Kích thước kernel\n",
    "- P = Padding (mặc định = 0 cho MaxPooling)\n",
    "- S = Stride\n",
    "\n",
    "**Tại vị trí MaxPool đầu tiên (a), kích thước đầu vào là 112×112×32**\n",
    "\n",
    "#### Trường hợp 1: MaxPool 2×2 với stride=2 (Original)\n",
    "$$\\text{Output} = \\left\\lfloor \\frac{112 - 2 + 0}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{110}{2} \\right\\rfloor + 1 = 55 + 1 = 56$$\n",
    "**Kích thước đầu ra: 56×56×32**\n",
    "\n",
    "#### Trường hợp 2: MaxPool 3×3 với stride=2 (Modified)\n",
    "$$\\text{Output} = \\left\\lfloor \\frac{112 - 3 + 0}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{109}{2} \\right\\rfloor + 1 = 54 + 1 = 55$$\n",
    "**Kích thước đầu ra: 55×55×32**\n",
    "\n",
    "### So sánh hai trường hợp:\n",
    "\n",
    "| Đặc điểm | MaxPool 2×2 (s=2) | MaxPool 3×3 (s=2) |\n",
    "|----------|-------------------|-------------------|\n",
    "| Kích thước đầu ra | 56×56×32 | 55×55×32 |\n",
    "| Tổng số pixels | 3,136 | 3,025 |\n",
    "| Giảm so với đầu vào | 75% | ~75.9% |\n",
    "| Vùng receptive field | 2×2 = 4 pixels | 3×3 = 9 pixels |\n",
    "| Thông tin bị mất | Ít hơn | Nhiều hơn |\n",
    "\n",
    "### Tác động của thay đổi:\n",
    "\n",
    "1. **Kích thước giảm 1 pixel mỗi chiều**: Từ 56×56 xuống 55×55\n",
    "2. **Receptive field lớn hơn**: Mỗi giá trị đầu ra đại diện cho vùng 3×3 thay vì 2×2\n",
    "3. **Mất nhiều thông tin chi tiết hơn**: Kernel lớn hơn có thể bỏ qua các đặc trưng nhỏ\n",
    "4. **Tăng tính bất biến**: Nhưng có thể làm giảm độ chính xác của vị trí đặc trưng\n",
    "\n",
    "**Lưu ý**: Hình vẽ ghi 56×56×24 sau MaxPool là **SAI**. Kích thước đúng phải là 56×56×32 vì MaxPooling không thay đổi số kênh (channels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996d82c",
   "metadata": {},
   "source": [
    "## Question 3.2.b) Skip Connection Analysis (Component b)\n",
    "\n",
    "### Xác định loại kết nối:\n",
    "\n",
    "**Component (b) trong hình là \"Skip Connection\" (Residual Connection / Shortcut Connection)**\n",
    "\n",
    "Trong kiến trúc được cho, có **hai skip connections** xuất phát từ sau lớp MaxPool đầu tiên:\n",
    "- **Skip 1 (bên trái)**: Kết nối từ sau MaxPool1 đến sau Conv layer thứ 4 (sau 2 lớp Conv 5×5)\n",
    "- **Skip 2 (component b, bên phải)**: Kết nối từ sau MaxPool1 đến sau Conv layer thứ 6 (sau 2 lớp Conv 3×3 tiếp theo)\n",
    "\n",
    "### Cách thức hoạt động:\n",
    "\n",
    "```\n",
    "                    ┌─────────────────────────────────────────────────────────┐\n",
    "                    │                                                         │ Skip 2 (b)\n",
    "                    │    ┌─────────────────────────────┐                      │\n",
    "                    │    │                             │ Skip 1               │\n",
    "                    │    │                             │                      │\n",
    "Input ─► MaxPool ──►├────┼─► Conv5x5 ─► Conv5x5 ──(+)──┼─► Conv3x3 ─► Conv3x3 ──(+)──► ...\n",
    "                         │                             │                      │\n",
    "                         └─────────────────────────────┘                      │\n",
    "                                                                              │\n",
    "                         └────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Công thức toán học:**\n",
    "\n",
    "Thay vì chỉ học ánh xạ $H(x)$, mạng học hàm residual $F(x)$:\n",
    "\n",
    "$$y = F(x) + x$$\n",
    "\n",
    "Trong đó:\n",
    "- $x$: Đầu vào của skip connection\n",
    "- $F(x)$: Hàm được học bởi các lớp tích chập\n",
    "- $y$: Đầu ra sau khi cộng\n",
    "\n",
    "Nếu kích thước/số kênh khác nhau, cần projection:\n",
    "$$y = F(x) + W_s \\cdot x$$\n",
    "\n",
    "Với $W_s$ là phép biến đổi 1×1 convolution để khớp kích thước.\n",
    "\n",
    "### Lợi ích của Skip Connections:\n",
    "\n",
    "1. **Giải quyết vấn đề Vanishing Gradient**:\n",
    "   - Gradient có thể truyền trực tiếp qua skip connection\n",
    "   - Ngăn gradient trở nên quá nhỏ khi truyền ngược qua nhiều lớp\n",
    "   - Cho phép huấn luyện mạng sâu hơn (100+ layers)\n",
    "\n",
    "2. **Học Residual dễ hơn**:\n",
    "   - Thay vì học toàn bộ ánh xạ, chỉ cần học \"phần bổ sung\"\n",
    "   - Nếu identity mapping là tối ưu, F(x) chỉ cần học = 0\n",
    "   - Dễ tối ưu hóa hơn\n",
    "\n",
    "3. **Cải thiện tốc độ hội tụ**:\n",
    "   - Huấn luyện nhanh hơn do gradient flow tốt hơn\n",
    "   - Giảm số epoch cần thiết\n",
    "\n",
    "4. **Tăng cường biểu diễn đặc trưng**:\n",
    "   - Kết hợp đặc trưng ở nhiều mức độ trừu tượng\n",
    "   - Low-level features (edges) được preserve và kết hợp với high-level features\n",
    "\n",
    "5. **Ngăn ngừa Degradation Problem**:\n",
    "   - Mạng sâu không bị giảm hiệu năng so với mạng nông\n",
    "   - Đảm bảo ít nhất đạt được performance của identity mapping\n",
    "\n",
    "### Đặc điểm trong kiến trúc này:\n",
    "\n",
    "Kiến trúc sử dụng **Dual Skip Connections**:\n",
    "- Skip 1 ngắn: Bảo tồn thông tin sau 2 lớp Conv\n",
    "- Skip 2 dài (b): Bảo tồn thông tin sau 4 lớp Conv\n",
    "\n",
    "Điều này tạo ra:\n",
    "- **Multi-scale feature fusion**: Kết hợp đặc trưng ở nhiều độ sâu\n",
    "- **Dense gradient pathways**: Nhiều đường để gradient truyền ngược\n",
    "- **Richer feature representations**: Biểu diễn phong phú hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e160c",
   "metadata": {},
   "source": [
    "## Question 3.2.c) Global Max Pooling (GMP) Definition and Proposed Placement\n",
    "\n",
    "### Định nghĩa Global Max Pooling (GMP):\n",
    "\n",
    "**Global Max Pooling (GMP)** là một kỹ thuật pooling lấy giá trị **lớn nhất** từ **toàn bộ feature map** cho mỗi channel.\n",
    "\n",
    "**Công thức toán học:**\n",
    "$$\\text{GMP}(X_c) = \\max_{i,j} X_c(i, j)$$\n",
    "\n",
    "Trong đó:\n",
    "- $X_c$: Feature map của channel thứ c\n",
    "- $i, j$: Vị trí không gian trong feature map\n",
    "- Kết quả: 1 giá trị scalar cho mỗi channel\n",
    "\n",
    "**Ví dụ:**\n",
    "- Đầu vào: 14×14×112 (feature map)\n",
    "- Sau GMP: 1×1×112 → có thể reshape thành vector 112 chiều\n",
    "\n",
    "### So sánh các loại Pooling:\n",
    "\n",
    "| Loại | Công thức | Đầu ra |\n",
    "|------|-----------|--------|\n",
    "| Max Pooling (local) | max trong vùng K×K | Giảm H, W theo stride |\n",
    "| Global Max Pooling | max toàn bộ H×W | 1×1×C |\n",
    "| Global Average Pooling | mean toàn bộ H×W | 1×1×C |\n",
    "\n",
    "### Ưu điểm của GMP:\n",
    "\n",
    "1. **Giảm đáng kể số tham số**:\n",
    "   - Không cần Flatten layer tạo ra vector khổng lồ\n",
    "   - Ví dụ: 14×14×112 = 21,952 → 112\n",
    "\n",
    "2. **Chống overfitting**:\n",
    "   - Ít tham số hơn = ít khả năng overfit\n",
    "\n",
    "3. **Tính bất biến vị trí cao**:\n",
    "   - Đặc trưng quan trọng nhất được giữ lại bất kể vị trí\n",
    "\n",
    "4. **Interpretability**:\n",
    "   - Mỗi kênh đại diện cho một đặc trưng cụ thể\n",
    "\n",
    "### Vị trí đề xuất cho GMP:\n",
    "\n",
    "**Đề xuất**: Chèn GMP **thay thế Flatten layer** hoặc **sau MaxPool cuối cùng, trước Flatten**.\n",
    "\n",
    "**Lý do:**\n",
    "1. Tại vị trí này (sau Conv cuối), feature maps đã chứa các đặc trưng high-level\n",
    "2. GMP sẽ giảm kích thước từ 7×7×112 = 5,488 xuống còn 112\n",
    "3. Giảm số tham số của Dense layer đầu tiên đáng kể\n",
    "4. Phù hợp với các mạng hiện đại như ResNet, Inception\n",
    "\n",
    "### Sơ đồ mạng sau khi thêm GMP:\n",
    "\n",
    "```\n",
    "                                        INPUT\n",
    "                                    (224×224×3)\n",
    "                                         │\n",
    "                                         ▼\n",
    "                              ┌─────────────────────┐\n",
    "                              │   Conv 3×3 (s=2)    │\n",
    "                              │    + BN + ReLU      │\n",
    "                              └─────────────────────┘\n",
    "                                    112×112×32\n",
    "                                         │\n",
    "                                         ▼\n",
    "                              ┌─────────────────────┐\n",
    "                              │   Conv 3×3 (s=1)    │\n",
    "                              │    + BN + ReLU      │\n",
    "                              └─────────────────────┘\n",
    "                                    112×112×32\n",
    "                                         │\n",
    "                                         ▼\n",
    "                              ┌─────────────────────┐\n",
    "                              │  MaxPool 2×2 (s=2)  │ ◄── Component (a)\n",
    "                              └─────────────────────┘\n",
    "                                     56×56×32\n",
    "                                         │\n",
    "           ┌─────────────────────────────┼─────────────────────────────┐\n",
    "           │                             │                             │\n",
    "      Skip 1                        Main Path                     Skip 2 (b)\n",
    "           │                             │                             │\n",
    "           │                             ▼                             │\n",
    "           │                  ┌─────────────────────┐                  │\n",
    "           │                  │   Conv 5×5 (s=1)    │                  │\n",
    "           │                  │    + BN + ReLU      │                  │\n",
    "           │                  └─────────────────────┘                  │\n",
    "           │                         56×56×40                          │\n",
    "           │                             │                             │\n",
    "           │                             ▼                             │\n",
    "           │                  ┌─────────────────────┐                  │\n",
    "           │                  │   Conv 5×5 (s=1)    │                  │\n",
    "           │                  │    + BN + ReLU      │                  │\n",
    "           │                  └─────────────────────┘                  │\n",
    "           │                         56×56×40                          │\n",
    "           │                             │                             │\n",
    "           └──────────► (+) ◄────────────┘                             │\n",
    "                         │                                             │\n",
    "                         ▼                                             │\n",
    "              ┌─────────────────────┐                                  │\n",
    "              │   Conv 3×3 (s=1)    │                                  │\n",
    "              │    + BN + ReLU      │                                  │\n",
    "              └─────────────────────┘                                  │\n",
    "                     56×56×80                                          │\n",
    "                         │                                             │\n",
    "                         ▼                                             │\n",
    "              ┌─────────────────────┐                                  │\n",
    "              │   Conv 3×3 (s=1)    │                                  │\n",
    "              │    + BN + ReLU      │                                  │\n",
    "              └─────────────────────┘                                  │\n",
    "                     56×56×80                                          │\n",
    "                         │                                             │\n",
    "                         └──────────────────────► (+) ◄────────────────┘\n",
    "                                                  │\n",
    "                                                  ▼\n",
    "                                       ┌─────────────────────┐\n",
    "                                       │   Conv 3×3 (s=2)    │\n",
    "                                       │    + BN + ReLU      │\n",
    "                                       └─────────────────────┘\n",
    "                                             28×28×112\n",
    "                                                  │\n",
    "                                                  ▼\n",
    "                                       ┌─────────────────────┐\n",
    "                                       │   Conv 3×3 (s=2)    │\n",
    "                                       │    + BN + ReLU      │\n",
    "                                       └─────────────────────┘\n",
    "                                             14×14×112\n",
    "                                                  │\n",
    "                                                  ▼\n",
    "                                       ┌─────────────────────┐\n",
    "                                       │  MaxPool 2×2 (s=2)  │\n",
    "                                       └─────────────────────┘\n",
    "                                              7×7×112\n",
    "                                                  │\n",
    "                                                  ▼\n",
    "                                ┌───────────────────────────────┐\n",
    "                                │  ★ GLOBAL MAX POOLING (GMP) ★ │  ◄── NEW LAYER\n",
    "                                └───────────────────────────────┘\n",
    "                                              1×1×112\n",
    "                                                  │\n",
    "                                                  ▼\n",
    "                                       ┌─────────────────────┐\n",
    "                                       │   Dense 1 (512)     │\n",
    "                                       │       ReLU          │\n",
    "                                       └─────────────────────┘\n",
    "                                                  │\n",
    "                                                  ▼\n",
    "                                       ┌─────────────────────┐\n",
    "                                       │   Dense 2 (128)     │\n",
    "                                       │       ReLU          │\n",
    "                                       └─────────────────────┘\n",
    "                                                  │\n",
    "                                                  ▼\n",
    "                                       ┌─────────────────────┐\n",
    "                                       │   Dense 3 (7)       │\n",
    "                                       │     Softmax         │\n",
    "                                       └─────────────────────┘\n",
    "                                                  │\n",
    "                                                  ▼\n",
    "                                              OUTPUT\n",
    "                                           (7 classes)\n",
    "```\n",
    "\n",
    "### Lưu ý về các giá trị SAI trong hình gốc:\n",
    "\n",
    "1. **56×56×24** sau MaxPool1 → **SAI**, đúng phải là **56×56×32** (MaxPool không thay đổi channels)\n",
    "2. **14×14×112** sau MaxPool2 → **SAI**, đúng phải là **7×7×112** (14/2 = 7)\n",
    "3. **Dense 3, 10** → **SAI** cho bài toán này, đúng phải là **Dense 3, 7** (7 emotion classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44f90d",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 3.3: Implementation of the Deep Learning Architecture (2 marks)\n",
    "---\n",
    "\n",
    "Triển khai kiến trúc Deep Learning theo sơ đồ đã cho, bao gồm:\n",
    "- Dual Skip Connections (2 đường skip chạy song song)\n",
    "- Các lớp Conv, BatchNorm, ReLU, MaxPool\n",
    "- Dense layers cho classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebdf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "DATA_DIR = 'Data'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    1: 'Surprise',\n",
    "    2: 'Fear', \n",
    "    3: 'Disgust',\n",
    "    4: 'Happiness',\n",
    "    5: 'Sadness',\n",
    "    6: 'Anger',\n",
    "    7: 'Neutral'\n",
    "}\n",
    "\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, img_size=224):\n",
    "    \"\"\"Load images from directory structure.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in range(1, 8):\n",
    "        folder_path = os.path.join(data_dir, str(label))\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            continue\n",
    "        \n",
    "        image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"Loading {EMOTION_LABELS[label]} ({label}): {len(image_files)} images\")\n",
    "        \n",
    "        for img_file in tqdm(image_files, desc=f\"Loading {EMOTION_LABELS[label]}\", leave=False):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            \n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = img.resize((img_size, img_size))\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                images.append(img_array)\n",
    "                labels.append(label - 1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading Training Dataset...\")\n",
    "X_train, y_train = load_dataset(TRAIN_DIR, IMG_SIZE)\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "\n",
    "print(\"\\nLoading Testing Dataset...\")\n",
    "X_test, y_test = load_dataset(TEST_DIR, IMG_SIZE)\n",
    "print(f\"\\nTesting set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_train_normalized = X_train.astype('float32') / 255.0\n",
    "X_test_normalized = X_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_onehot = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Validation split\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_normalized, y_train_onehot, \n",
    "    test_size=0.15, \n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Final training set: {X_train_final.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(x, filters, kernel_size, strides=1, padding='same', name=None):\n",
    "    \"\"\"\n",
    "    Convolutional block with BatchNormalization and ReLU activation.\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor\n",
    "        filters: Number of filters\n",
    "        kernel_size: Size of convolution kernel\n",
    "        strides: Stride for convolution\n",
    "        padding: Padding type\n",
    "        name: Base name for the layers\n",
    "    \n",
    "    Returns:\n",
    "        Output tensor after Conv2D + BatchNorm + ReLU\n",
    "    \"\"\"\n",
    "    if name:\n",
    "        conv_name = f'{name}_conv'\n",
    "        bn_name = f'{name}_bn'\n",
    "    else:\n",
    "        conv_name = None\n",
    "        bn_name = None\n",
    "    \n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, \n",
    "                      use_bias=False, name=conv_name)(x)\n",
    "    x = layers.BatchNormalization(name=bn_name)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f433e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_architecture(input_shape=(224, 224, 3), num_classes=7, use_gmp=False):\n",
    "    \"\"\"\n",
    "    Build the custom architecture based on the provided diagram.\n",
    "    \n",
    "    Architecture features:\n",
    "    - Initial Conv layers with stride for downsampling\n",
    "    - MaxPooling layer\n",
    "    - Dual skip connections (splitting at MaxPool, merging at different points)\n",
    "    - Final Conv layers and Dense layers for classification\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input images\n",
    "        num_classes: Number of output classes\n",
    "        use_gmp: Whether to use Global Max Pooling (Question 3.2.c modification)\n",
    "    \n",
    "    Returns:\n",
    "        Keras Model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input\n",
    "    inputs = layers.Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # ==================== INITIAL STEM ====================\n",
    "    # Conv 3x3 (s=2) + BN + ReLU → 112x112x32\n",
    "    x = conv_bn_relu(inputs, filters=32, kernel_size=3, strides=2, name='stem_conv1')\n",
    "    \n",
    "    # Conv 3x3 (s=1) + BN + ReLU → 112x112x32\n",
    "    x = conv_bn_relu(x, filters=32, kernel_size=3, strides=1, name='stem_conv2')\n",
    "    \n",
    "    # MaxPool 2x2 (s=2) → 56x56x32\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2, name='maxpool1')(x)\n",
    "    # Note: The diagram shows 56x56x24 which is INCORRECT. Correct is 56x56x32\n",
    "    \n",
    "    # ==================== DUAL SKIP CONNECTIONS ====================\n",
    "    # At this point, the tensor splits into 3 paths:\n",
    "    # - Skip connection 1 (left): goes directly to merge point after Conv 5x5 layers\n",
    "    # - Main path (middle): goes through all Conv layers\n",
    "    # - Skip connection 2 (right, component b): goes directly to merge point after Conv 3x3 layers\n",
    "    \n",
    "    skip1 = x  # 56x56x32 - will merge after 2x Conv 5x5\n",
    "    skip2 = x  # 56x56x32 - will merge after 2x Conv 3x3 (component b)\n",
    "    \n",
    "    # ==================== FIRST CONV BLOCK (5x5) ====================\n",
    "    # Conv 5x5 (s=1) + BN + ReLU → 56x56x40\n",
    "    x = conv_bn_relu(x, filters=40, kernel_size=5, strides=1, name='block1_conv1')\n",
    "    \n",
    "    # Conv 5x5 (s=1) + BN + ReLU → 56x56x40\n",
    "    x = conv_bn_relu(x, filters=40, kernel_size=5, strides=1, name='block1_conv2')\n",
    "    \n",
    "    # ==================== FIRST ADD (Skip 1 merges here) ====================\n",
    "    # Need to match channels: skip1 is 32 channels, x is 40 channels\n",
    "    skip1_proj = layers.Conv2D(40, kernel_size=1, strides=1, padding='same', \n",
    "                                use_bias=False, name='skip1_projection')(skip1)\n",
    "    skip1_proj = layers.BatchNormalization(name='skip1_bn')(skip1_proj)\n",
    "    \n",
    "    x = layers.Add(name='add1')([x, skip1_proj])\n",
    "    x = layers.ReLU(name='add1_relu')(x)\n",
    "    \n",
    "    # ==================== SECOND CONV BLOCK (3x3) ====================\n",
    "    # Conv 3x3 (s=1) + BN + ReLU → 56x56x80\n",
    "    x = conv_bn_relu(x, filters=80, kernel_size=3, strides=1, name='block2_conv1')\n",
    "    \n",
    "    # Conv 3x3 (s=1) + BN + ReLU → 56x56x80\n",
    "    x = conv_bn_relu(x, filters=80, kernel_size=3, strides=1, name='block2_conv2')\n",
    "    \n",
    "    # ==================== SECOND ADD (Skip 2/Component b merges here) ====================\n",
    "    # Need to match channels: skip2 is 32 channels, x is 80 channels\n",
    "    skip2_proj = layers.Conv2D(80, kernel_size=1, strides=1, padding='same',\n",
    "                                use_bias=False, name='skip2_projection')(skip2)\n",
    "    skip2_proj = layers.BatchNormalization(name='skip2_bn')(skip2_proj)\n",
    "    \n",
    "    x = layers.Add(name='add2')([x, skip2_proj])\n",
    "    x = layers.ReLU(name='add2_relu')(x)\n",
    "    \n",
    "    # ==================== THIRD CONV BLOCK (3x3 with stride) ====================\n",
    "    # Conv 3x3 (s=2) + BN + ReLU → 28x28x112\n",
    "    x = conv_bn_relu(x, filters=112, kernel_size=3, strides=2, name='block3_conv1')\n",
    "    \n",
    "    # Conv 3x3 (s=2) + BN + ReLU → 14x14x112\n",
    "    x = conv_bn_relu(x, filters=112, kernel_size=3, strides=2, name='block3_conv2')\n",
    "    \n",
    "    # MaxPool 2x2 (s=2) → 7x7x112\n",
    "    # Note: The diagram shows 14x14x112 which is INCORRECT. Correct is 7x7x112\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2, name='maxpool2')(x)\n",
    "    \n",
    "    # ==================== CLASSIFICATION HEAD ====================\n",
    "    if use_gmp:\n",
    "        # Global Max Pooling (as proposed in 3.2.c) → 1x1x112\n",
    "        x = layers.GlobalMaxPooling2D(name='global_max_pooling')(x)\n",
    "    else:\n",
    "        # Flatten Layer → 7*7*112 = 5488\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "    \n",
    "    # Dense 1, 512, ReLU\n",
    "    x = layers.Dense(512, activation='relu', name='dense1')(x)\n",
    "    x = layers.Dropout(0.5, name='dropout1')(x)\n",
    "    \n",
    "    # Dense 2, 128, ReLU\n",
    "    x = layers.Dense(128, activation='relu', name='dense2')(x)\n",
    "    x = layers.Dropout(0.3, name='dropout2')(x)\n",
    "    \n",
    "    # Dense 3, num_classes (7 for FER, not 10 as shown in diagram)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='Custom_FER_Model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model (without GMP - as per original diagram)\n",
    "print(\"=\" * 60)\n",
    "print(\"BUILDING CUSTOM ARCHITECTURE (without GMP)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model_original = build_custom_architecture(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3), \n",
    "    num_classes=NUM_CLASSES,\n",
    "    use_gmp=False\n",
    ")\n",
    "\n",
    "model_original.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a060114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with GMP (as proposed in 3.2.c)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BUILDING CUSTOM ARCHITECTURE (with GMP)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model_with_gmp = build_custom_architecture(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3), \n",
    "    num_classes=NUM_CLASSES,\n",
    "    use_gmp=True\n",
    ")\n",
    "\n",
    "model_with_gmp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare parameter counts\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PARAMETER COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Original model (Flatten): {model_original.count_params():,} parameters\")\n",
    "print(f\"Model with GMP:           {model_with_gmp.count_params():,} parameters\")\n",
    "print(f\"Parameter reduction:      {model_original.count_params() - model_with_gmp.count_params():,} parameters\")\n",
    "print(f\"Reduction percentage:     {((model_original.count_params() - model_with_gmp.count_params()) / model_original.count_params()) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3601ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which model to train (you can change this)\n",
    "USE_GMP = True  # Set to True to use Global Max Pooling\n",
    "\n",
    "if USE_GMP:\n",
    "    model = model_with_gmp\n",
    "    model_name = \"Custom_FER_with_GMP\"\n",
    "else:\n",
    "    model = model_original\n",
    "    model_name = \"Custom_FER_Original\"\n",
    "\n",
    "print(f\"\\nUsing model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.15,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        f'best_{model_name}.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"TRAINING {model_name.upper()}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_datagen.flow(X_train_final, y_train_final, batch_size=BATCH_SIZE),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db603d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[0].set_title(f'{model_name} - Accuracy Over Epochs', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[1].set_title(f'{model_name} - Loss Over Epochs', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'training_history_{model_name}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a98420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "model = keras.models.load_model(f'best_{model_name}.keras')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_normalized, y_test_onehot, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7166c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred_proba = model.predict(X_test_normalized, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Classification report\n",
    "emotion_names = [EMOTION_LABELS[i+1] for i in range(7)]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_pred_classes, target_names=emotion_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=emotion_names, yticklabels=emotion_names)\n",
    "plt.title(f'Confusion Matrix - {model_name}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'confusion_matrix_{model_name}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac731e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "            xticklabels=emotion_names, yticklabels=emotion_names)\n",
    "plt.title(f'Normalized Confusion Matrix - {model_name}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'confusion_matrix_normalized_{model_name}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PER-CLASS ACCURACY\")\n",
    "print(\"=\" * 60)\n",
    "for i, emotion in enumerate(emotion_names):\n",
    "    class_accuracy = cm[i, i] / cm[i, :].sum()\n",
    "    print(f\"{emotion}: {class_accuracy:.4f} ({cm[i, i]}/{cm[i, :].sum()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample predictions\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 10))\n",
    "fig.suptitle(f'Sample Predictions - {model_name}', fontsize=14, fontweight='bold')\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_test), 15, replace=False)\n",
    "\n",
    "for idx, ax in enumerate(axes.flatten()):\n",
    "    sample_idx = sample_indices[idx]\n",
    "    \n",
    "    ax.imshow(X_test[sample_idx])\n",
    "    \n",
    "    true_label = emotion_names[y_test[sample_idx]]\n",
    "    pred_label = emotion_names[y_pred_classes[sample_idx]]\n",
    "    confidence = y_pred_proba[sample_idx][y_pred_classes[sample_idx]]\n",
    "    \n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    ax.set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2f}', \n",
    "                 fontsize=9, color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'sample_predictions_{model_name}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save(f'{model_name}_final.keras')\n",
    "print(f\"\\nFinal model saved as '{model_name}_final.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70214f12",
   "metadata": {},
   "source": [
    "## Final Summary and Performance Analysis\n",
    "\n",
    "### Về kích thước được ghi SAI trong hình gốc:\n",
    "\n",
    "1. **56×56×24 sau MaxPool1**: SAI - Đúng phải là **56×56×32** (MaxPool không thay đổi số channels)\n",
    "2. **14×14×112 sau MaxPool2**: SAI - Đúng phải là **7×7×112** (14÷2=7)\n",
    "3. **Dense 3, 10**: SAI cho bài toán FER - Đúng phải là **7** (7 emotion classes)\n",
    "\n",
    "### Về Dual Skip Connections:\n",
    "\n",
    "Kiến trúc này sử dụng 2 skip connections xuất phát cùng một điểm (sau MaxPool1) nhưng merge ở 2 vị trí khác nhau:\n",
    "\n",
    "1. **Skip 1 (ngắn)**: Merge sau 2 lớp Conv 5×5 → Bảo tồn features cấp thấp\n",
    "2. **Skip 2 (dài - component b)**: Merge sau 4 lớp Conv → Cho phép gradient flow xa hơn\n",
    "\n",
    "Lợi ích:\n",
    "- Cải thiện gradient flow\n",
    "- Multi-scale feature fusion\n",
    "- Tăng khả năng học complex patterns\n",
    "\n",
    "### Đề xuất cải tiến với Global Max Pooling:\n",
    "\n",
    "GMP giúp:\n",
    "- Giảm đáng kể số parameters\n",
    "- Tăng khả năng generalization\n",
    "- Chống overfitting hiệu quả hơn\n",
    "\n",
    "### Các metric đánh giá đã sử dụng:\n",
    "\n",
    "1. **Accuracy**: Tỷ lệ dự đoán đúng tổng thể\n",
    "2. **Precision**: Độ chính xác của positive predictions\n",
    "3. **Recall**: Khả năng phát hiện positive samples\n",
    "4. **F1-Score**: Trung bình điều hòa của Precision và Recall\n",
    "5. **Confusion Matrix**: Ma trận hiển thị chi tiết dự đoán đúng/sai cho từng class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e29895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL SUMMARY - PART 3.2 & 3.3\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "print(f\"Total Parameters: {model.count_params():,}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  - Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"  - Loss: {test_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nKey Architecture Features:\")\n",
    "print(f\"  - Dual Skip Connections\")\n",
    "print(f\"  - BatchNormalization after each Conv layer\")\n",
    "print(f\"  - Global Max Pooling: {'Yes' if USE_GMP else 'No'}\")\n",
    "print(f\"  - Dropout for regularization\")\n",
    "print(f\"  - Data Augmentation during training\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"END OF PART 3.2 & 3.3\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
